# Project Description

This project's goal is to get familiar with data modeling in PostgreSQL and performing ETL jobs in Python. First, we define fact and dimension tables for a star schema for a particular analytic focus, and write an ETL pipeline that transfers data from files in two local directories into these tables in Postgres using Python and SQL. 

## Data Model 

![plot](./pictures/ERD.png)

## ETL Job

## SQL queries

## Quick start

- First:

Install Anaconda and create a new virtual environment:

- Second:

Run the shell script "run_scripts.sh" to install the requirements and create the schema, tables, populate the tables with data. Open the terminal window (Linux) and run the following command:
./scripts/shell/run_scripts.sh

- Third:

Go to notebooks directory and run the tests.ipynb jupyter notebook. Run the cells to test the queries